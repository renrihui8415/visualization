{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview: Visualization for Toronto Ward Budgets (Year 2024 to Year 2033)\n",
    "\n",
    "## Prerequisites\n",
    "- **PowerBI**\n",
    "- **Data Visualization**\n",
    "- **Data Analysis**\n",
    "\n",
    "## 1. Data Source and Description\n",
    "\n",
    "### 1.1 Data Source\n",
    "The data used in this project is **automatically** retrieved and downloaded by Python from various Excel files available at the following link. [Toronto Open Data](https://open.toronto.ca/dataset/budget-capital-budget-plan-by-ward-10-yr-approved/\n",
    "). The downloaded data is stored in the data folder within the current year's work directory.\n",
    "\n",
    "<img src=\"data files.png\" alt=\"data files\" width=\"400\" height=\"400\">\n",
    "\n",
    "\n",
    "### 1.2 Data Description\n",
    "\n",
    "Each file contains financial data for 44 (25 from 2019) wards in Toronto, covering the time span **from 2010 to 2033**. The columns detail annual budgets, and key columns of interest are:\n",
    "\n",
    "- `Ward/Project Number`: Identifier for each ward and project.\n",
    "- `Year` columns: Columns that represent different years' budget data.\n",
    "\n",
    "To illustrate the budget allocation for Toronto over the next 10 years, we will analyze the latest 2024-2033 budget file.\n",
    "\n",
    "## 2. Project Objective (Data Visualization)\n",
    "\n",
    "The primary objective is to use Power BI to create an **interactive** plot that visualizes Toronto's budget planning for the next 10 years.\n",
    "\n",
    "### 2.1 Chart Features\n",
    "- **Vertical Comparison**: Compare the budget changes of the same ward across different years, showing how the budget evolves over time for that specific ward.\n",
    "- **Horizontal Comparison**: Compare the budgets of different wards for the same year, highlighting how budgets vary among wards in a given year.\n",
    "\n",
    "![Dynamic Map Chart](viz_by_powerbi.gif)\n",
    "\n",
    "## 3. Data Preparing \n",
    "\n",
    "To improve efficiency, the data required for Power BI visualization will be automated and retrieved by Python.\n",
    "\n",
    "### 3.1 Reading Excel Files\n",
    "\n",
    "### 3.2 Extracting and Cleaning Data (ETL)\n",
    "\n",
    "## 4. Data Calculating for Visualization \n",
    "\n",
    "Prepare the data for visualization by:\n",
    "\n",
    "- Aggreating budgets for each ward.\n",
    "- Adding new columns as needed.\n",
    "- Filling missing values with fillna.\n",
    "- Ensuring data accuracy for accurate visualizations.\n",
    "\n",
    "<img src=\"viz_by_powerbi.png\" alt=\"PowerBI\" width=\"600\" height=\"600\">\n",
    "\n",
    "## 5. Data Visualization (Map Chart)\n",
    "   - Use PowerBI to create an interactive map chart.\n",
    "   - Display annual budget plans for each ward, showing how budgets change both from year to year and across different wards.\n",
    "   \n",
    "\n",
    "(End)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages have been installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 0.1 The following function installs/tests the major required packages for this script\n",
    "\n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        import_name = package\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"{package} installed successfully.\")\n",
    "    finally:\n",
    "        globals()[package] = __import__(import_name)\n",
    "\n",
    "\n",
    "import_packages = ['selenium', 'webdriver_manager', 'xlrd', 'openpyxl', 'xls2xlsx']\n",
    "\n",
    "for package in import_packages:\n",
    "    install_and_import(package)\n",
    "print('Packages have been installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get download links\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Download files\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Data ETL\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from xls2xlsx import XLS2XLSX\n",
    "\n",
    "# Data Integration\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Suppress specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "source_data_link         = 'https://open.toronto.ca/dataset/budget-capital-budget-plan-by-ward-10-yr-approved/'\n",
    "source_button_XPATH      = '//*[@id=\"header-Download\"]/div/h3/button'\n",
    "link_XPATH               = '//*[@id=\"table-resources\"]'\n",
    "download_folder          = 'data'\n",
    "ward_column_list         = ['Ward', 'Ward/Project Number', 'Ward/Project Num.', 'Ward Name']\n",
    "inserted_column          = 'Year'\n",
    "# rename_column_1          = 'Budget_Year_1'\n",
    "# rename_column_2          = 'Budget_Year_2'\n",
    "extracted_data_file      = 'budget_data.csv'\n",
    "report_data_file         = 'report_data.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparing\n",
    " \n",
    "- **2.1 Function to get download links for multiple Excel files**\n",
    "\n",
    "**_Please note that this code will automatically use Google Chrome to search for download links. If you do not have the Google Chrome browser installed, please manually download the data from the source data link (in the previous cell) to the 'data' folder in your current working directory._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url, button_XPATH, links_area_XPATH):\n",
    "\n",
    "    # Set up Selenium options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode (no browser window)\n",
    "\n",
    "    # Initialize the WebDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Open the target URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the button to be clickable and click it\n",
    "    time.sleep(1)  # Adjust wait time as needed\n",
    "    button = driver.find_element(By.XPATH, button_XPATH)  # Adjust XPath as needed\n",
    "    button.click()\n",
    "\n",
    "    # Wait for the content to load\n",
    "    time.sleep(1)  # Adjust wait time as needed\n",
    "\n",
    "    # Find the specific area containing the links\n",
    "    links_area = driver.find_element(By.XPATH, links_area_XPATH)\n",
    "\n",
    "    # Find all links within the specified area\n",
    "    links = links_area.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "    # Extract all download links (including .xls and .xlsx) that contain \"download\"\n",
    "    download_links = [\n",
    "        link.get_attribute('href') for link in links\n",
    "        if 'download' in link.get_attribute('href').lower() and re.search(r'\\.(xls|xlsx)$', link.get_attribute('href'), re.IGNORECASE)\n",
    "    ]\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "    \n",
    "    return download_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.2 Function to download Files using the download links**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(download_links, download_folder):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    for link in download_links:\n",
    "        # Extract the file name from the link\n",
    "        file_name = os.path.join(download_folder, link.split('/')[-1])\n",
    "\n",
    "        # Send a GET request to download the file\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()  # Ensure we notice bad responses\n",
    "\n",
    "        # Write the file to the specified folder\n",
    "        with open(file_name, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        print(f\"Downloaded {file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.3 Data ETL (Extraction, Transformation, Loading)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.1 Subfunction 1 to get the year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_column(name):\n",
    "    # Function to check if a column name can be converted to an int\n",
    "    try:\n",
    "        return int(name)\n",
    "    except:        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.2 Subfunction 2 to convert .xls to .xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xls_to_xlsx(xls_path, xlsx_path):\n",
    "    \n",
    "    xls_file = XLS2XLSX(xls_path)\n",
    "    xls_file.to_xlsx(xlsx_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.3 Subfunction 3 to fill the unmerged cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_unmerged_cells(file_path):\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        for merge in list(sheet.merged_cells.ranges):\n",
    "            min_col, min_row, max_col, max_row = merge.bounds\n",
    "            top_left_cell_value = sheet.cell(row=min_row, column=min_col).value\n",
    "            sheet.unmerge_cells(str(merge))\n",
    "            for row in range(min_row, max_row + 1):\n",
    "                for col in range(min_col, max_col + 1):\n",
    "                    sheet.cell(row=row, column=col).value = top_left_cell_value\n",
    "    workbook.save(file_path)\n",
    "    print(f\"Unmerged cells have been saved for Year: {(os.path.basename(file_path))[0:4]}\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.4 Subfunction 4 to convert string to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.5 Subfunction 5 to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_path, ward_column_list, sheet_name=None):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    year_number = file_name[0:4]\n",
    "    filtered_data = None\n",
    "    # 1) Read the Excel file and convert the data to string temporarily\n",
    "    if sheet_name:\n",
    "        try: \n",
    "            # Read a specific sheet into a DataFrame\n",
    "            excel_data = pd.read_excel(file_path, header=None, sheet_name=sheet_name, dtype=str,engine='openpyxl')\n",
    "        except: \n",
    "            excel_data = pd.read_excel(file_path, header=None, sheet_name=sheet_name, dtype=str,engine='xlrd')\n",
    "        # Wrap DataFrame in a dictionary to handle uniformly\n",
    "        excel_data = {sheet_name: excel_data}\n",
    "    else:\n",
    "        try:\n",
    "            # Read all sheets into a dictionary\n",
    "            excel_data = pd.read_excel(file_path, header=None, dtype=str, sheet_name=None, engine='openpyxl')\n",
    "        except:\n",
    "            excel_data = pd.read_excel(file_path, header=None, dtype=str, sheet_name=None, engine='xlrd')\n",
    "    # 2) Iterate over the sheets and find the actual header\n",
    "    for sheet_name, sheet_data in excel_data.items():\n",
    "        # Flatten the DataFrame to a Series for easier searching\n",
    "        # flat_series = sheet_data.stack().astype(str)\n",
    "        \n",
    "        ward_row_index = None\n",
    "        # Check if 'ward_column' is found in any cell\n",
    "        for ward_column in ward_column_list:\n",
    "            # print(f'Searching for Ward_column : {ward_column}')\n",
    "            # if flat_series.str.contains(ward_column, case=False, na=False).any():\n",
    "\n",
    "            # Find all the index of the row containing 'Ward/Project Number' or 'Ward'\n",
    "            matched_rows = sheet_data[sheet_data.apply(lambda row: row.astype(str).str.strip() == ward_column).any(axis=1)]\n",
    "            if len(matched_rows) == 0:\n",
    "                # The result contains nothing\n",
    "                continue\n",
    "            elif len(matched_rows) ==1 and int(year_number)<2019:\n",
    "                ward_row_index = matched_rows.index[0]\n",
    "            else:\n",
    "                # Multiple values have been found                                  \n",
    "                # ward_column =='Ward' \n",
    "                # print(matched_rows)\n",
    "                for index, row in matched_rows.iterrows():\n",
    "                    # print(f'Index is \"{index}\", Row is \"{row}\"')\n",
    "                    # Check if the column to the right of 'Ward' contains 'Project Name'\n",
    "                    ward_col_index = row[row.astype(str).str.strip() == ward_column].index[0]\n",
    "                    # print(f\"Ward_col_index is {ward_col_index}\")\n",
    "                    # if ward_col_index + 1 < len(sheet_data.columns):\n",
    "                    #     # print(len(row))\n",
    "                    #     # print(type(row))\n",
    "                    project_col = row[row.astype(str).str.strip() == 'Project Name']\n",
    "                    # print(f\"Project_col is {project_col}\")\n",
    "                    if project_col.empty:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if int(year_number) >=2019:\n",
    "                            ward_row_index = index\n",
    "                        \n",
    "                        elif int(year_number) == 2010:\n",
    "                            project_col_index = project_col.index[0]\n",
    "                            if  ward_col_index+1 == project_col_index :\n",
    "                                ward_column = row[ward_col_index]\n",
    "                                # 'Ward' is a desired column name\n",
    "                                ward_row_index = index\n",
    "                            break\n",
    "                 \n",
    "            if ward_row_index >=0:\n",
    "                # Ward Column is found    \n",
    "                print(f\"'{ward_column}' found in the sheet '{sheet_name}'.\")\n",
    "                above_budget_cell_value = None\n",
    "                row_values = sheet_data.iloc[ward_row_index].tolist()\n",
    "               \n",
    "                if 'Budget' in row_values:\n",
    "                    # Some files contain the current year number above the \"Budget\" cell\n",
    "                    budget_cell_index = row_values.index('Budget')\n",
    "\n",
    "                    # Ensure the index is not None:\n",
    "                    if budget_cell_index > 0:\n",
    "                        above_budget_cell_value = sheet_data.iloc[ward_row_index - 1, budget_cell_index]\n",
    "                        \n",
    "                # 4) Remove all rows above the 'Ward/Project Number' row and reset the index\n",
    "                if ward_row_index >0 :\n",
    "                    data = sheet_data.iloc[ward_row_index:].reset_index(drop=True)\n",
    "                else:\n",
    "                    data = sheet_data.reset_index(drop=True)\n",
    "                # 5) Set the first row of data as column headers\n",
    "                new_header = data.iloc[0]\n",
    "                data = data[1:]\n",
    "                data.columns = new_header\n",
    "                if above_budget_cell_value:\n",
    "                    data.rename(columns={'Budget': above_budget_cell_value}, inplace=True)\n",
    "                \n",
    "                # 6) Extract all column names and find columns that can be converted to year\n",
    "                year_columns = [(col, get_year_from_column(col)) for col in data.columns]\n",
    "                year_columns = [col for col, year in year_columns if year is not None]\n",
    "                \n",
    "                # 7) Get all year columns\n",
    "                # Note: copy() is used to prevent year columns from changes\n",
    "                selected_columns = year_columns.copy()\n",
    "                # 8) Keep only necessary columns\n",
    "                if int(year_number)>=2019:\n",
    "                    selected_columns.extend([ward_column, 'Ward Number'])\n",
    "                else:\n",
    "                    selected_columns.append(ward_column)\n",
    "                selected_data = data[selected_columns]\n",
    "                    \n",
    "                # 9) Filter the data \n",
    "                selected_data.loc[:,ward_column] = selected_data[ward_column].fillna(' ')\n",
    "                # print(selected_data['Ward Number'].unique())\n",
    "                # print(year_number)\n",
    "                if year_number == '2010':\n",
    "                    filtered_data = selected_data[selected_data[ward_column].str.startswith('Ward')]\n",
    "                    # print(f'filtered_data is {filtered_data}')\n",
    "                    filtered_data = filtered_data.dropna(subset=selected_columns)\n",
    "                elif int(year_number) >=2019:\n",
    "                    # As Ward Number has been chosen, those indicating non-numerical value will be removed\n",
    "                    selected_data = selected_data[selected_data['Ward Number'].apply(lambda x: str(x).isdigit())]\n",
    "                    # print(selected_data.head(5))\n",
    "                    original_data= selected_data.copy()\n",
    "                    \n",
    "                    # print(original_data['Ward Number'].unique())\n",
    "                    for column in year_columns:\n",
    "                        # print(column)\n",
    "                        original_data[column] = original_data[column].apply(to_numeric)\n",
    "                    # print(original_data['Ward Number'].unique())\n",
    "                    # print(original_data)\n",
    "                    # List of columns to sum\n",
    "                    columns_to_sum = year_columns  \n",
    "                    # Perform the sum operation and keep all other columns\n",
    "                    original_data[columns_to_sum] = original_data.groupby('Ward Number')[columns_to_sum].transform('sum')\n",
    "                    filtered_data = original_data\n",
    "                    # filtered_data= original_data.groupby('Ward Number').sum().reset_index()\\\n",
    "                    # Try to avoid using groupby this way, the non-numerical columns will be grouped as well\n",
    "                    filtered_data = filtered_data.rename(columns={\n",
    "                        'Ward Number':'Ward_Number', \n",
    "                        ward_column:ward_column_list[0],\n",
    "                    })\n",
    "                    # print(filtered_data)\n",
    "                else:\n",
    "                    filtered_data = selected_data[selected_data[ward_column].str.endswith('Total')]\n",
    "\n",
    "                # 10) Drop duplicates and null values\n",
    "                filtered_data = filtered_data.drop_duplicates()\n",
    "                filtered_data = filtered_data.dropna()\n",
    "    # print(filtered_data)    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3.6 Function for Data ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_etl(download_folder, ward_column_list, sheet_name=None):    \n",
    "    \n",
    "\n",
    "    # 1) Get the absolute path of the download folder\n",
    "    folder_path = os.path.abspath(download_folder)\n",
    "\n",
    "    # 2) Iterate over all Excel files in the folder to look for the data file\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xlsx') or file_name.endswith('.xls'):\n",
    "            year_numbers = file_name[0:9]\n",
    "            if '2024-2033-' in file_name:\n",
    "                \n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                if file_name.endswith('.xls') :\n",
    "                    # !This is very important! The merged cells in the Excel must be unmerged and filled before loading the values into a dataframe\n",
    "                    xlsx_path = file_path.replace('.xls','.xlsx')\n",
    "                    # print(file_name)\n",
    "                    convert_xls_to_xlsx(file_path,xlsx_path)\n",
    "                    fill_unmerged_cells(xlsx_path)\n",
    "                    continue\n",
    "                \n",
    "                print(f'Extracting data for Year \"{year_numbers}\"....')\n",
    "                sheet_names = pd.ExcelFile(file_path).sheet_names\n",
    "                filtered_data = data_processing(file_path, ward_column_list, sheet_names[0])\n",
    "    \n",
    "    # Unpivot\n",
    "    filtered_data = pd.melt(filtered_data, id_vars=[ward_column_list[0], 'Ward_Number'], var_name='Year', value_name='Budget')\n",
    "    # print(filtered_data)\n",
    "    return filtered_data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Main() Function to streamline and automate data visualization, data processing and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. Download links have been obtained.\n",
      "Downloaded data/2024-2033-capital-budget-and-plan-details.xlsx\n",
      "Step 2. Data files have been download in '/Users/julia/Desktop/Life/DSI/9. visualization/04_cohort_three/live_code/data'. \n",
      "Extracting data for Year \"2024-2033\"....\n",
      "'Ward' found in the sheet '2024-2032'.\n",
      "Step 3. Budget data has been extracted and saved.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # 1. Get the download links from data source\n",
    "    download_links = get_links(source_data_link, source_button_XPATH, link_XPATH)\n",
    "\n",
    "    # Print all download links\n",
    "    # print(\"Download links:\")\n",
    "    # for link in download_links:\n",
    "    #     print(link)\n",
    "    print(\"Step 1. Download links have been obtained.\")\n",
    "\n",
    "    # 2. Download files using the download links\n",
    "    # Only download the data for this project\n",
    "    for link in download_links:\n",
    "        if '2024-2033-' in link:\n",
    "            download_links = [link]\n",
    "            download_files(download_links, download_folder)\n",
    "\n",
    "    print(f\"Step 2. Data files have been download in '{os.path.abspath(download_folder)}'. \")\n",
    "    \n",
    "    # 3. Data Process (ETL)\n",
    "    budget_data = data_etl(download_folder, ward_column_list, None)\n",
    "    if budget_data.empty:\n",
    "        return f\"Budget_data not found in the {download_folder} folder.\"\n",
    "    # print(budget_data.head(5))\n",
    "    \n",
    "    # Save the extracted data into .csv file\n",
    "    budget_data.to_csv(extracted_data_file)\n",
    "    print(\"Step 3. Budget data has been extracted and saved.\")\n",
    "\n",
    "    # # 4. Data Calculation for Reporting(Visualization)\n",
    "    # report_data = data_integrating(extracted_data_file,ward_column_list)\n",
    "    # report_data.to_csv(report_data_file)\n",
    "    # print('Step 4. Report data have been calculated and saved.')\n",
    "    # # print(report_data.head(5))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
